{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>This is the code for COM3013 Coursework</h1>\n",
    "<h2>Mofe Awosanya, Ebose Odijie, Hishaam Khan</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "\n",
    "# Set the sharing strategy\n",
    "mp.set_sharing_strategy('file_system')\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "x_list = []\n",
    "y_list = []\n",
    "\n",
    "for inputs, labels in trainloader:\n",
    "    x_list.append(inputs)\n",
    "    y_list.append(labels)\n",
    "\n",
    "x = torch.cat(x_list, dim=0)\n",
    "y = torch.cat(y_list, dim=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 120)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        x = x.view(-1, 256 * 4 * 4)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.relu5(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = Model()\n",
    "model = model.float()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "loss_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        default_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        default_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "            print('fc3 Weights: ')\n",
    "\n",
    "print('Finished using initial SGD Optimization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "gradient_descent_data = []\n",
    "i=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        gradient_descent_data.append((i, 100 * correct // total))\n",
    "        i+=1\n",
    "\n",
    "\n",
    "print(f'Model Accuracy on Testing Images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.fc3.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.init as init\n",
    "\n",
    "# def initialise_weights(layer):\n",
    "#     if isinstance(layer, nn.Linear):\n",
    "#         init.xavier_uniform_(layer.weight)\n",
    "#         nn.init.zeros_(layer.bias)\n",
    "        \n",
    "# model.fc3.apply(initialise_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_model.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import creator, base, tools, algorithms\n",
    "from sympy.combinatorics.graycode import GrayCode\n",
    "from sympy.combinatorics.graycode import gray_to_bin\n",
    "from sympy.combinatorics.graycode import bin_to_gray\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "pop_size = 5 #population size\n",
    "num_of_bits = 8 #number of bits in a chromosome\n",
    "iterations = 5 #number of generations\n",
    "dspInterval = 1\n",
    "\n",
    "cross_prob = 0.75 #crossover probability\n",
    "mutate_prob = 0.95 #mutation probability\n",
    "num_elitists = 5 #the number of elite individuals selected\n",
    "\n",
    "maxnum = 2*num_of_bits\n",
    "\n",
    "fc1shape = 256*4*4*120\n",
    "fc2shape = 120*84\n",
    "fc3shape = 84*10\n",
    "\n",
    "chromosome_length = (84*10)+1\n",
    "\n",
    "flip_prob = 0.1\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "# toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "# toolbox.register(\"individual\", tools.initRepeat, creator.Individual, np.random.randint, 2, num_of_bits)\n",
    "# toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "# toolbox.register(\"evaluate\", evaluate)\n",
    "# toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "# toolbox.register(\"mutate\", tools.mutFlipBit, indpb=flip_prob)\n",
    "# toolbox.register(\"select\", tools.selTournament, fit_attr=\"fitness\")\n",
    "\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n",
    "    toolbox.attr_bool, num_of_bits*(chromosome_length))\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "def retrieve_weights():\n",
    "    fc3list = model.fc3.weight.reshape(fc3shape).tolist()\n",
    "\n",
    "    fc3bias = model.fc3.bias.tolist()\n",
    "\n",
    "    weights = fc3list + fc3bias\n",
    "\n",
    "    return weights\n",
    "\n",
    "def real_to_chromosome(weight):\n",
    "    weight = weight/20\n",
    "    if weight < -1:\n",
    "        weight = -1\n",
    "    if weight > 1:\n",
    "        weight = 1\n",
    "    integerPart = int(maxnum * (weight + 1 ) / 2)\n",
    "    if (integerPart == maxnum):\n",
    "        integerPart -= 1\n",
    "    chromosome = [int(d) for d in str(bin(integerPart))[2:]]\n",
    "    while (len(chromosome) < num_of_bits):\n",
    "        chromosome.insert(0, 0)\n",
    "    indasstring=''.join(map(str, chromosome))\n",
    "    chromosome=bin_to_gray(indasstring)\n",
    "    output=[]\n",
    "    for digit in chromosome:\n",
    "        output.append(int(digit))\n",
    "\n",
    "    return output\n",
    "\n",
    "def chromosome_to_real(c):\n",
    "    indasstring=''.join(map(str, c))\n",
    "    degray=gray_to_bin(indasstring)\n",
    "    numasint=int(degray, 2)\n",
    "    numinrange=-1.0+2.0*numasint/maxnum\n",
    "    return numinrange*20\n",
    "\n",
    "def separatevariables(v):\n",
    "    sep = []\n",
    "    for i in range (0,num_of_bits*(chromosome_length),num_of_bits):\n",
    "        sep.append(chromosome_to_real(v[i:i+num_of_bits]))\n",
    "    return sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(individual):\n",
    "    weights = separatevariables(individual)\n",
    "    weights = np.asarray(weights)\n",
    "\n",
    "    model.fc3.weight = torch.nn.Parameter(torch.from_numpy(weights[:fc3shape].reshape(84, 10).T).float())\n",
    "    model.fc3.bias = torch.nn.Parameter(torch.from_numpy(weights[[chromosome_length - 1]]).float())\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in trainloader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return 1 - accuracy\n",
    "\n",
    "    \n",
    "\n",
    "toolbox.register(\"evaluate\", calc_fitness)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=flip_prob)\n",
    "toolbox.register(\"select\", tools.selTournament, fit_attr=\"fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "popa = toolbox.population(n=pop_size)\n",
    "pop=[]\n",
    "for individual in popa:\n",
    "    sep = separatevariables(individual)\n",
    "    weightlist=[]\n",
    "    for weight in sep:\n",
    "        weightlist+=real_to_chromosome(weight)\n",
    "    pop.append(creator.Individual(weightlist))\n",
    "\n",
    "fitnesses = list(map(toolbox.evaluate, pop))\n",
    "for ind, fit in zip(pop, fitnesses):\n",
    "    ind.fitness.values = (fit,)\n",
    "\n",
    "print(\" Evaluated %i individuals\" % len(pop))\n",
    "\n",
    "fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "g = 0\n",
    "\n",
    "while g < iterations:\n",
    "    g = g + 1\n",
    "    print(\"-- Generation %i -- \" % g)\n",
    "\n",
    "    offspring = tools.selBest(pop, num_elitists)\n",
    "    offspring += toolbox.select(pop, len(pop)-num_elitists, 2)\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "    randomnum = random.random()\n",
    "    print(randomnum)\n",
    "\n",
    "    for child1, child2 in zip(offspring[:-1:2], offspring[1::2]):\n",
    "        if randomnum < cross_prob:\n",
    "            print(\"Crosssover\")\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "        else:\n",
    "            print(\"No Crossover\")\n",
    "            \n",
    "            \n",
    "    for mutant in offspring[2::]:\n",
    "        if randomnum < mutate_prob:\n",
    "            print(\"Mutation\")\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "        else:\n",
    "            print(\"No Mutation\")\n",
    "\n",
    "    for individual in offspring:\n",
    "        weights=separatevariables(individual)\n",
    "        weights=np.asarray(weights)\n",
    "    \n",
    "        model.fc3.weight = torch.nn.Parameter(torch.from_numpy(weights[:fc3shape].reshape(84, 10).T).float())\n",
    "        model.fc3.bias = torch.nn.Parameter(torch.from_numpy(weights[[chromosome_length - 1]]).float())\n",
    "\n",
    "        for epoch in range(2):\n",
    "            for inputs, labels in trainloader:\n",
    "                default_optimizer.zero_grad()\n",
    "                outputs=model(inputs)\n",
    "                loss=loss_func(outputs, labels)\n",
    "                # Print the loss for each iteration\n",
    "                loss.backward()\n",
    "                default_optimizer.step()\n",
    "            print(f'epoch %i' % epoch)\n",
    "\n",
    "        outputs=model(inputs)\n",
    "        loss=loss_func(outputs, labels)\n",
    "        print('Post loss.item:', loss.item())\n",
    "        fc3list = model.fc3.weight.reshape(fc3shape).tolist()\n",
    "        fc3bias = model.fc3.bias.reshape(1).tolist()\n",
    "        weights = fc3list + fc3bias\n",
    "\n",
    "        individual.clear()\n",
    "        newInd=[]\n",
    "        for index in range(len(weights)):\n",
    "            chromosome = real_to_chromosome(weights[index])\n",
    "            newInd += chromosome\n",
    "        newInd = creator.Individual(newInd)\n",
    "        offspring.remove(individual)\n",
    "        offspring.append(newInd)\n",
    "    \n",
    "    pop[:] = offspring\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = (fit,)\n",
    "\n",
    "    fits = [ind.fitness.values[0] for ind in pop]\n",
    "    loss_values.append(min(fits))\n",
    "\n",
    "    if g%dspInterval == 0:\n",
    "        fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "        length = len(pop)\n",
    "        mean = sum(fits) / length\n",
    "        sum2 = sum(x*x for x in fits)\n",
    "        std = abs(sum2 / length - mean**2)**0.5\n",
    "\n",
    "        print(\" Min %s\" % min(fits))\n",
    "        print(\" Max %s\" % max(fits))\n",
    "        print(\" Avg %s\" % mean)\n",
    "        print(\" Std %s\" % std)\n",
    "\n",
    "print(\"-- Completed Evolution --\")\n",
    "\n",
    "best_individual = tools.selBest(pop, 1)[0]\n",
    "print(\"Loss of Genetic Algorithm Optimiser on Final Layer: %s\" % (calc_fitness(best_individual)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=separatevariables(best_individual)\n",
    "weights=np.asarray(weights)\n",
    "\n",
    "model.fc3.weight = torch.nn.Parameter(torch.from_numpy(weights[:fc3shape].reshape(84, 10).T).float())\n",
    "model.fc3.bias = torch.nn.Parameter(torch.from_numpy(weights[[chromosome_length - 1]]).float())\n",
    "\n",
    "genetic_algorithm_data = []\n",
    "\n",
    "i = 0\n",
    "# Test the accuracy on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        genetic_algorithm_data.append((i, 100 * correct // total))\n",
    "        i += 1\n",
    "\n",
    "print(f'Model Accuracy on Testing Images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = toolbox.population(n=pop_size)\n",
    "pop=[]\n",
    "for individual in population:\n",
    "    sep = separatevariables(individual)\n",
    "    print(sep)\n",
    "    weightlist=[]\n",
    "    for weight in sep:\n",
    "        weightlist+=real_to_chromosome(weight)\n",
    "    pop.append(creator.Individual(weightlist))\n",
    "\n",
    "fitnesses = list(map(toolbox.evaluate, population))\n",
    "for ind, fit in zip(population, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "while g < iterations:\n",
    "    g = g + 1\n",
    "    print(\"-- Generation %i -- \" % g)\n",
    "    \n",
    "    offspring = toolbox.select(population, len(population))\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "    \n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < cross_prob:\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "            \n",
    "    for mutant in offspring:\n",
    "        if random.random() < mutate_prob:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "            \n",
    "    # Replace the old population with the offspring\n",
    "    population[:] = offspring\n",
    "    \n",
    "    if g%dspInterval == 0:\n",
    "        fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "    length = len(pop)\n",
    "    mean = sum(fits) / length\n",
    "    sum2 = sum(x*x for x in fits)\n",
    "    std = abs(sum2 / length - mean**2)**0.5\n",
    "\n",
    "    print(\" Min %s\" % min(fits))\n",
    "    print(\" Max %s\" % max(fits))\n",
    "    print(\" Avg %s\" % mean)\n",
    "    print(\" Std %s\" % std)\n",
    "    \n",
    "best_individual = tools.selBest(population, k=1)[0]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(model, data_loader, loss_func):\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_weights(model, weights):\n",
    "    weights = np.asarray(weights)\n",
    "    \n",
    "    model.fc3.weight = torch.nn.Parameter(torch.from_numpy(weights[:fc3shape].reshape(84, 10).T).float())\n",
    "    model.fc3.bias = torch.nn.Parameter(torch.from_numpy(weights[[chromosome_length - 1]]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_search(model, trainloader, loss_func, initial_delta=1.0, delta_decay=0.5, max_iter=10, min_delta=1e-6):\n",
    "    best_loss = calc_loss(model, trainloader, loss_func)\n",
    "    current_weights = retrieve_weights()\n",
    "    delta = initial_delta\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        improved = False\n",
    "\n",
    "        # Explore adding delta\n",
    "        new_weights = [w + delta for w in current_weights]\n",
    "        update_model_weights(model, new_weights)\n",
    "        loss = calc_loss(model, trainloader, loss_func)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            current_weights = new_weights\n",
    "            improved = True\n",
    "\n",
    "        # Explore subtracting delta\n",
    "        new_weights = [w - delta for w in current_weights]\n",
    "        update_model_weights(model, new_weights)\n",
    "        loss = calc_loss(model, trainloader, loss_func)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            current_weights = new_weights\n",
    "            improved = True\n",
    "\n",
    "        if not improved:\n",
    "            delta *= delta_decay  # Reduce delta if no improvement\n",
    "\n",
    "        # Print progress\n",
    "        progress_percentage = (iteration + 1) / max_iter\n",
    "        print(f'Iteration {iteration}, Best Loss: {best_loss}, Delta: {delta}, Progress: {progress_percentage:.2f}%')\n",
    "\n",
    "        # Stopping criterion based on delta\n",
    "        if delta < min_delta:\n",
    "            print(f'Stopping criterion met: Delta is below {min_delta}')\n",
    "            break\n",
    "\n",
    "    # Set model weights to the best found\n",
    "    update_model_weights(model, current_weights)\n",
    "    print(\"Loss of Pattern Search Optimiser on the Final Layer: \", best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pattern search\n",
    "pattern_search(model, trainloader, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "pattern_search_data = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        pattern_search_data.append((i, 100 * correct // total))\n",
    "        i+=1\n",
    "\n",
    "print(f'Model Accuracy on Testing Images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_gradient, accuracy_gradient = zip(*gradient_descent_data)\n",
    "evaluations_psearch, accuracy_psearch = zip(*pattern_search_data)\n",
    "evaluations_genetic, accuracy_genetic = zip(*genetic_algorithm_data)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(evaluations_gradient, accuracy_gradient, label=\"SGD\")\n",
    "plt.plot(evaluations_psearch, accuracy_psearch, label=\"Pattern Search\")\n",
    "plt.plot(evaluations_genetic, accuracy_genetic, label=\"Genetic Algorithm\")\n",
    "\n",
    "\n",
    "plt.title('Performance Trend of Learning Methods')\n",
    "plt.xlabel('Number of Evaluations of the Objective Function')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
