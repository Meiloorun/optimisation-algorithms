{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>This is the code for COM3013 Coursework</h1>\n",
    "<h2>Mofe Awosanya, Ebose Odijie, Hishaam Khan</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>This is the code for COM3013 Coursework</h1>\n",
    "<h2>Mofe Awosanya, Ebose Odijie, Hishaam Khan</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>This is the code for COM3013 Coursework</h1>\n",
    "<h2>Mofe Awosanya, Ebose Odijie, Hishaam Khan</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if machine is using CUDA GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using pytorch here to get the CIFAR10 dataset and set the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "x_list = []\n",
    "y_list = []\n",
    "\n",
    "for inputs, labels in trainloader:\n",
    "    x_list.append(inputs)\n",
    "    y_list.append(labels)\n",
    "\n",
    "x = torch.cat(x_list, dim=0)\n",
    "y = torch.cat(y_list, dim=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to create the forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 120)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        x = x.view(-1, 256 * 4 * 4)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.relu5(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = Model()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to define the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()\n",
    "loss_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to Define the Optimisation Function for the majority of the layers, for the final layer we will be using our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the setup for the genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import creator, base, tools, algorithms\n",
    "from sympy.combinatorics.graycode import GrayCode\n",
    "from sympy.combinatorics.graycode import gray_to_bin\n",
    "from sympy.combinatorics.graycode import bin_to_gray\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "pop_size = 50 #population size\n",
    "num_of_bits = 30 #number of bits in a chromosome\n",
    "iterations = 30 #number of generations\n",
    "dspInterval = 5\n",
    "\n",
    "cross_prob = 0.75 #crossover probability\n",
    "mutate_prob = 0.95 #mutation probability\n",
    "num_elitists = 5 #the number of elite individuals selected\n",
    "\n",
    "maxnum = 2*num_of_bits\n",
    "\n",
    "fc1shape = 256*4*4*120\n",
    "fc2shape = 120*84\n",
    "fc3shape = 84*10\n",
    "\n",
    "chromosome_length = (3+1)*120+(120+1)*84+(84+1)*10\n",
    "\n",
    "flip_prob = 1. / (chromosome_length * num_of_bits/30)\n",
    "\n",
    "def retrieve_weights():\n",
    "    fc1list = model.fc1.weight.reshape(fc1shape).tolist()\n",
    "    fc2list = model.fc2.weight.reshape(fc2shape).tolist()\n",
    "    fc3list = model.fc3.weight.reshape(fc3shape).tolist()\n",
    "\n",
    "    fc1bias = model.fc1.bias.reshape(120).tolist()\n",
    "    fc2bias = model.fc2.bias.reshape(84).tolist()\n",
    "    fc3bias = model.fc3.bias.reshape(10).tolist()\n",
    "\n",
    "    weights = fc1list + fc2list + fc3list + fc1bias + fc2bias + fc3bias\n",
    "\n",
    "    return weights\n",
    "\n",
    "def real_to_chromosome(weight):\n",
    "    weight = weight/20\n",
    "    if weight < -1:\n",
    "        weight = -1\n",
    "    if weight > 1:\n",
    "        weight = 1\n",
    "    integerPart = int(maxnum * (weight + 1 ) / 2)\n",
    "    if (integerPart == maxnum):\n",
    "        integerPart -= 1\n",
    "    chromosome = [int(d) for d in str(bin(integerPart))[2:]]\n",
    "    while (len(chromosome) < num_of_bits):\n",
    "        chromosome.insert(0, 0)\n",
    "    indasstring=''.join(map(str, chromosome))\n",
    "    chromosome=bin_to_gray(indasstring)\n",
    "    output=[]\n",
    "    for digit in chromosome:\n",
    "        output.append(int(digit))\n",
    "\n",
    "    return output\n",
    "\n",
    "def chromosome_to_real(c):\n",
    "    indasstring=''.join(map(str, c))\n",
    "    degray=gray_to_bin(indasstring)\n",
    "    numasint=int(degray, 2)\n",
    "    numinrange=-1.0+2.0*numasint/maxnum\n",
    "    return numinrange*20\n",
    "\n",
    "def separatevariables(v):\n",
    "    sep = []\n",
    "    for i in range (0,numOfBits*(Chrom_length),numOfBits):\n",
    "        sep.append(chrom2real(v[i:i+numOfBits]))\n",
    "    return sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to train our model with the default optimiser for 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "    running_loss=0.0\n",
    "\n",
    "    outputs = model(x)\n",
    "    loss = loss_func(outputs, y)\n",
    "    default_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    default_optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    if i % 2000 == 1999:\n",
    "        print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "        running_loss = 0.0\n",
    "\n",
    "outputs = model(x)\n",
    "loss = loss_func(outputs, y)\n",
    "print('Finished using SGD Optimsation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitness Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(individual):\n",
    "    weights = np.asarray(weights)\n",
    "\n",
    "    model.fc1.weight = torch.nn.Parameter(torch.from_numpy(weights[:(fc1shape)].reshape(2, 120).T))\n",
    "    model.fc2.weight = torch.nn.Parameter(torch.from_numpy(weights[fc1shape:fc1shape+fc2shape].reshape(120, 84)))\n",
    "    model.fc3.weight = torch.nn.Parameter(torch.from_numpy(weights[fc1shape+fc2shape: fc1shape+fc2shape+fc3shape].reshape(84, 10).T))\n",
    "\n",
    "    model.fc1.bias = torch.nn.Parameter(torch.from_numpy(weights[fc1shape+fc2shape+fc3shape: fc1shape+fc2shape+fc3shape+120]))\n",
    "    model.fc2.bias = torch.nn.Parameter(torch.from_numpy(weights[fc1shape+fc2shape+fc3shape+120: fc1shape+fc2shape+fc3shape+120+84]))\n",
    "    model.fc3.bias = torch.nn.Parameter(torch.from_numpy(np.asarray(weights[chromosome_length-1])))\n",
    "\n",
    "    out = model(x)\n",
    "    loss = loss_func(out, y)\n",
    "    return loss.item()\n",
    "\n",
    "toolbox.register(\"evaluate\", calc_fitness)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=flip_prob)\n",
    "toolbox.register(\"select\", tools.selTournament, fit_attr=\"fitness\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the weights from the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popa = toolbox.population(n=pop_size)\n",
    "pop=[]\n",
    "for individual in popa:\n",
    "    sep = separatevariables(individual)\n",
    "    weightlist=[]\n",
    "    for weight in sep:\n",
    "        weightlist+=real_to_chromosome(weight)\n",
    "    pop.append(creator.Individual(weightlist))\n",
    "\n",
    "fitnesses = list(map(toolbox.evaluate, pop))\n",
    "for ind, fit in zip(pop, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "print(\" Evaluated %i individuals\" % len(pop))\n",
    "\n",
    "fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "g = 0\n",
    "\n",
    "while g < iterations:\n",
    "    g = g + 1\n",
    "    print(\"-- Generation %i -- \" % g)\n",
    "\n",
    "    offspring = tools.selBest(pop, num_elitists)\n",
    "    offspring += toolbox.select(pop, len(pop)-num_elitists, 2)\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    for child1, child2 in zip(offspring[4::2], offspring[5::2]):\n",
    "        if random.random() < cross_prob:\n",
    "            toolbox.mate(child1, child2)\n",
    "\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring[4::]:\n",
    "        if random.random() < mutate_prob:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "\n",
    "    for individual in offspring:\n",
    "        weights = retrieve_weights()\n",
    "        individual.clear()\n",
    "        newInd=[]\n",
    "        for index in range(len(weights)):\n",
    "            chromosome = real_to_chromosome(weights[index])\n",
    "            newInd += chromosome\n",
    "        newInd = creator.Individual(newInd)\n",
    "        offspring.remove(individual)\n",
    "        offspring.append(newInd)\n",
    "    \n",
    "    pop[:] = offspring\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    fits = [ind.fitnesses.values[0] for ind in pop]\n",
    "    loss_values.append(min(fits))\n",
    "\n",
    "    if g%dspInterval == 0:\n",
    "        fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "        length = len(pop)\n",
    "        mean = sum(fits) / length\n",
    "        sum2 = sum(x*x for x in fits)\n",
    "        std = abs(sum2 / length - mean**2)**0.5\n",
    "\n",
    "        print(\" Min %s\" % min(fits))\n",
    "        print(\" Max %s\" % max(fits))\n",
    "        print(\" Avg %s\" % mean)\n",
    "        print(\" Std %s\" % std)\n",
    "\n",
    "print(\"-- Completed Evolution --\")\n",
    "\n",
    "best_individual = tools.selBest(pop, 1)[0]\n",
    "print(\"Fitness %s\" % (calc_fitness(best_individual)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_model.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets look at some of the testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to evaluate the model using the testing batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Model Accuracy on Testing Images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
